{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "from cpgqls_client import CPGQLSClient\n",
    "\n",
    "import mistralai\n",
    "\n",
    "from mistralai import Mistral\n",
    "from mistralai.models import UserMessage, AssistantMessage, SystemMessage\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"...\"\n",
    "repo_name = \"...\"\n",
    "api_key = \"...\"\n",
    "context = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joern_output_to_dict(out):\n",
    "    out = out['stdout']\n",
    "    tq = '\"\"\"'\n",
    "    start, end = out.find(tq) + len(tq), out.rfind(tq)\n",
    "    if start < 0 or end < 0 or end <= start:\n",
    "        raise \"something went wrong\"\n",
    "    out = out[start : end]\n",
    "    result = json.loads(out)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "server_endpoint = \"localhost:8080\"\n",
    "basic_auth_credentials = (\"username\", \"password\")\n",
    "joern_client = CPGQLSClient(server_endpoint, auth_credentials=basic_auth_credentials)\n",
    "\n",
    "result = joern_client.execute('close')\n",
    "\n",
    "\n",
    "def parse_joern_output(out):\n",
    "    out = out['stdout']\n",
    "    tq = '\"\"\"'\n",
    "    start, end = out.find(tq) + len(tq), out.rfind(tq)\n",
    "    if start < 0 or end < 0 or end <= start:\n",
    "        raise Exception(\"JSON extraction failed\")\n",
    "    out = out[start : end]\n",
    "    return json.loads(out)\n",
    "\n",
    "query_func = \"\"\"\n",
    "    cpg.method\n",
    "        .isExternal(false)\n",
    "        .whereNot(_.name(\"<.*\"))\n",
    "        .map(m => (m.name,\n",
    "                   m.code,\n",
    "                   m.call.whereNot(_.name(\"<.*\")).name.l,\n",
    "                   m.parameter.name.l,\n",
    "                   m.parameter.typeFullName.l,\n",
    "                   m.ast.isReturn.code.l,\n",
    "                   m.methodReturn.typeFullName,\n",
    "                  )\n",
    "            )\n",
    "        .toJsonPretty\n",
    "\"\"\"\n",
    "\n",
    "query = f'importCode(inputPath=\"{repo_path}\", projectName=\"{repo_name}\")'\n",
    "result = joern_client.execute(query)\n",
    "\n",
    "funcs_result = joern_client.execute(query_func)\n",
    "all_data = parse_joern_output(funcs_result)\n",
    "\n",
    "data = {\n",
    "    x['_1']: {\n",
    "        'code': x['_2'],\n",
    "        'calls': x['_3'],\n",
    "        'arg_names': x['_4'],\n",
    "        'arg_types': x['_5'],\n",
    "        'return_expressions': x['_6'],\n",
    "        'return_type': x['_7'],\n",
    "    }\n",
    "    for x in all_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data.values():\n",
    "    x['calls'] = set(filter(lambda y: y in data, x['calls']))\n",
    "    x['return_expressions'] = set(map(lambda s: s[7:-1], x['return_expressions']))\n",
    "    \n",
    "    if len(x['arg_names']) == 1 and x['arg_names'][0] == '':\n",
    "        x['arg_names'] = []\n",
    "        x['arg_types'] = []        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_client = Mistral(api_key=api_key)\n",
    "model = \"codestral-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_call_graph(root, depth=3):\n",
    "    queue = deque([root])\n",
    "    visited = set()\n",
    "    code = []\n",
    "    \n",
    "    while len(queue) > 0:\n",
    "        func_name = queue.popleft()\n",
    "        if func_name in visited:\n",
    "            continue\n",
    "        visited.add(func_name)\n",
    "        code.append(data[func_name]['code'])\n",
    "        queue += data[func_name]['calls']\n",
    "    \n",
    "    return '\\n\\n'.join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "output_file = \"llm_annotations.json\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    results = {}\n",
    "\n",
    "processed = 0\n",
    "\n",
    "for func_name, content in data.items():\n",
    "    if func_name in results:\n",
    "        continue\n",
    "    \n",
    "    time.sleep(5.0)\n",
    "    \n",
    "    if context:\n",
    "        code = bfs_call_graph(func_name)[:1000]\n",
    "    else:\n",
    "        code = content['code']\n",
    "\n",
    "    prompt = \"\"\"You are C developer. Your task is to answer questions on a code.\n",
    "    Which variables contain pointers to the memory allocated in function {func_name}, put the answer in \"allocated_variables\" field.\n",
    "    Which variables contain pointers to the memory deallocated in function {func_name}, put the answer in \"deallocated_variables\" field. \n",
    "    Return the ultimate answer in short JSON object.\n",
    "        \n",
    "    # code\n",
    "    {code}\"\"\".format(func_name=func_name, code=code)\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    chat_response = mistral_client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    raw_output = chat_response.choices[0].message.content\n",
    "    \n",
    "    try:\n",
    "        json_output = json.loads(raw_output)\n",
    "        \n",
    "        results[func_name] = {\n",
    "            \"allocated_variables\": json_output.get(\"allocated_variables\", []),\n",
    "            \"deallocated_variables\": json_output.get(\"deallocated_variables\", [])\n",
    "        }\n",
    "        \n",
    "        if processed % 10 == 0:\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "        \n",
    "        processed += 1\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"llm_annotations.json\", 'r') as f:\n",
    "    llm_results = json.load(f)\n",
    "\n",
    "for func_name in data:\n",
    "    if func_name in llm_results:\n",
    "        data[func_name][\"allocated_variables\"] = llm_results[func_name][\"allocated_variables\"]\n",
    "        data[func_name][\"deallocated_variables\"] = llm_results[func_name][\"deallocated_variables\"]\n",
    "\n",
    "annotations = {}\n",
    "ann_alloc = \"AllocSource::1\"\n",
    "ann_free = \"FreeSink::1\"\n",
    "log_entries = []\n",
    "\n",
    "for func_name, v in data.items():\n",
    "    if \"deallocated_variables\" not in v:\n",
    "        continue\n",
    "    \n",
    "    key = f\"{func_name}({func_name})\"\n",
    "    annotations[key] = [[] for _ in range(len(v[\"arg_names\"]) + 1)]\n",
    "    \n",
    "    for i, arg in enumerate(v[\"arg_names\"]):\n",
    "        if arg in v.get(\"deallocated_variables\", []):\n",
    "            annotations[key][i + 1] = [ann_free]\n",
    "        if arg in v.get(\"allocated_variables\", []):\n",
    "            annotations[key][i + 1] = [ann_alloc]\n",
    "    \n",
    "    for arg in v.get(\"return_expressions\", []):\n",
    "        if arg in v.get(\"deallocated_variables\", []):\n",
    "            annotations[key][0] = [ann_free]\n",
    "        if arg in v.get(\"allocated_variables\", []):\n",
    "            annotations[key][0] = [ann_alloc]\n",
    "    \n",
    "    log_entries.append({\n",
    "        \"function\": func_name,\n",
    "        \"key\": key,\n",
    "        \"annotations\": annotations[key],\n",
    "        \"arg_names\": v[\"arg_names\"],\n",
    "        \"allocated\": v.get(\"allocated_variables\", []),\n",
    "        \"deallocated\": v.get(\"deallocated_variables\", [])\n",
    "    })\n",
    "\n",
    "with open(\"annotations.json\", 'w') as f:\n",
    "    json.dump(annotations, f, indent=2)\n",
    "\n",
    "with open(\"annotation_log.json\", 'w') as f:\n",
    "    json.dump(log_entries, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем Joern для нахождения data-flow между парами аллокатор/деаллокатор\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"annotations.json\", 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "with open(\"annotation_log.json\", 'r') as f:\n",
    "    annotation_log = json.load(f)\n",
    "\n",
    "functions_with_return = []\n",
    "for entry in annotation_log:\n",
    "    if entry.get(\"allocated\") or entry.get(\"deallocated\"):\n",
    "        functions_with_return.append(entry[\"function\"])\n",
    "\n",
    "flow_results = []\n",
    "\n",
    "for i, func_a in enumerate(functions_with_return):\n",
    "    for j, func_b in enumerate(functions_with_return):\n",
    "            \n",
    "        ann_a = annotations.get(f\"{func_a}({func_a})\", [])\n",
    "        ann_b = annotations.get(f\"{func_b}({func_b})\", [])\n",
    "        \n",
    "        is_a_source = False\n",
    "        if ann_a and len(ann_a) > 0:\n",
    "            if ann_a[0] and any(\"AllocSource\" in a for a in ann_a[0]):\n",
    "                is_a_source = True\n",
    "        \n",
    "        is_b_sink = False\n",
    "        if ann_b and len(ann_b) > 1:\n",
    "            for ann in ann_b[1:]:\n",
    "                if ann and any(\"FreeSink\" in a for a in ann):\n",
    "                    is_b_sink = True\n",
    "                    break\n",
    "        \n",
    "        if is_a_source and is_b_sink:\n",
    "            query = f'''\n",
    "def source = cpg.method.name(\"{func_a}\").methodReturn\n",
    "def sink = cpg.method.name(\"{func_b}\").parameter\n",
    "\n",
    "sink.reachableByFlows(source).p\n",
    "'''\n",
    "            \n",
    "            result = joern_client.execute(query)\n",
    "            \n",
    "            if result.get('success') and result.get('stdout', '').strip():\n",
    "                stdout = result['stdout'].strip()\n",
    "                if stdout and '┌──' in stdout:\n",
    "                    flow_results.append({\n",
    "                        \"allocator\": func_a,\n",
    "                        \"deallocator\": func_b,\n",
    "                        \"query\": query,\n",
    "                        \"has_flow\": True\n",
    "                    })\n",
    "\n",
    "with open(\"alloc_free_flows.json\", 'w') as f:\n",
    "    json.dump(flow_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import deque\n",
    "\n",
    "with open(\"annotations.json\", 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "with open(\"annotation_log.json\", 'r') as f:\n",
    "    annotation_log = json.load(f)\n",
    "\n",
    "def get_subgraph_functions(root, max_depth=3):\n",
    "    queue = deque([(root, 0)])\n",
    "    visited = set()\n",
    "    subgraph = set()\n",
    "    \n",
    "    while queue:\n",
    "        current_func, depth = queue.popleft()\n",
    "        if current_func in visited or depth > max_depth:\n",
    "            continue\n",
    "        visited.add(current_func)\n",
    "        subgraph.add(current_func)\n",
    "        if current_func in data and 'calls' in data[current_func]:\n",
    "            for call in data[current_func]['calls']:\n",
    "                if call in data:\n",
    "                    queue.append((call, depth + 1))\n",
    "    return subgraph\n",
    "\n",
    "alloc_functions = []\n",
    "free_functions = []\n",
    "\n",
    "for entry in annotation_log:\n",
    "    func_name = entry[\"function\"]\n",
    "    anns = entry[\"annotations\"]\n",
    "    if anns and len(anns) > 0:\n",
    "        if anns[0] and any(\"AllocSource\" in a for a in anns[0]):\n",
    "            alloc_functions.append(func_name)\n",
    "    for ann in anns[1:]:\n",
    "        if ann and any(\"FreeSink\" in a for a in ann):\n",
    "            free_functions.append(func_name)\n",
    "            break\n",
    "\n",
    "target_functions = alloc_functions + free_functions\n",
    "\n",
    "functions_with_flows = []\n",
    "\n",
    "for func_name in data:\n",
    "    subgraph = get_subgraph_functions(func_name, max_depth=4)\n",
    "    \n",
    "    has_alloc = any(alloc in subgraph for alloc in alloc_functions)\n",
    "    has_free = any(free in subgraph for free in free_functions)\n",
    "    \n",
    "    if not (has_alloc and has_free):\n",
    "        continue\n",
    "    \n",
    "    for alloc in alloc_functions:\n",
    "        if alloc not in subgraph:\n",
    "            continue\n",
    "        for free in free_functions:\n",
    "            if free not in subgraph:\n",
    "                continue\n",
    "            \n",
    "            query = f'''\n",
    "def source = cpg.method(\"{func_name}\").call(\"{alloc}\")\n",
    "def sink = cpg.method(\"{func_name}\").call(\"{free}\").argument\n",
    "sink.reachableByFlows(source).l\n",
    "'''\n",
    "            \n",
    "            result = joern_client.execute(query)\n",
    "            \n",
    "            if result.get('success') and result.get('stdout', '').strip():\n",
    "                stdout = result['stdout'].strip()\n",
    "                if 'Path(' in stdout:\n",
    "                    functions_with_flows.append({\n",
    "                        \"function\": func_name,\n",
    "                        \"allocator\": alloc,\n",
    "                        \"deallocator\": free,\n",
    "                        \"has_flow\": True\n",
    "                    })\n",
    "\n",
    "output = []\n",
    "for item in functions_with_flows:\n",
    "    output.append(f\"Function: {item['function']}\")\n",
    "    output.append(f\"  Allocator: {item['allocator']}\")\n",
    "    output.append(f\"  Deallocator: {item['deallocator']}\")\n",
    "    output.append(\"\")\n",
    "\n",
    "with open(\"functions_with_flows.json\", 'w') as f:\n",
    "    json.dump(functions_with_flows, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"annotation_log.json\", 'r') as f:\n",
    "    annotation_log = json.load(f)\n",
    "\n",
    "alloc_functions = []\n",
    "free_functions = []\n",
    "\n",
    "for entry in annotation_log:\n",
    "    func_name = entry[\"function\"]\n",
    "    anns = entry[\"annotations\"]\n",
    "    \n",
    "    if anns and len(anns) > 0:\n",
    "        if anns[0] and any(\"AllocSource\" in a for a in anns[0]):\n",
    "            alloc_functions.append(func_name)\n",
    "    \n",
    "    for i, ann in enumerate(anns[1:], 1):\n",
    "        if ann and any(\"FreeSink\" in a for a in ann):\n",
    "            free_functions.append(func_name)\n",
    "            break\n",
    "\n",
    "with open(\"allocators.txt\", 'w') as f:\n",
    "    for func in sorted(alloc_functions):\n",
    "        f.write(func + \"\\n\")\n",
    "\n",
    "with open(\"deallocators.txt\", 'w') as f:\n",
    "    for func in sorted(free_functions):\n",
    "        f.write(func + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Спрашиваем модель считает ли она что найденная пара alloc/dealloc действительно является таковой\n",
    "\n",
    "import json\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "def bfs_call_graph(root, max_depth=3):\n",
    "    queue = deque([(root, 0)])\n",
    "    visited = set()\n",
    "    functions = []\n",
    "    \n",
    "    while queue:\n",
    "        func_name, depth = queue.popleft()\n",
    "        if func_name in visited or depth > max_depth:\n",
    "            continue\n",
    "        visited.add(func_name)\n",
    "        functions.append(func_name)\n",
    "        \n",
    "        if func_name in data and 'calls' in data[func_name]:\n",
    "            for call in data[func_name]['calls']:\n",
    "                if call in data:\n",
    "                    queue.append((call, depth + 1))\n",
    "    \n",
    "    code_parts = []\n",
    "    for func in functions:\n",
    "        if func in data:\n",
    "            code_parts.append(f\"// Function: {func}\\n{data[func]['code'][:1000]}\")\n",
    "    \n",
    "    return '\\n\\n'.join(code_parts)\n",
    "\n",
    "with open(\"functions_with_flows.json\", 'r') as f:\n",
    "    found_pairs = json.load(f)\n",
    "\n",
    "output_file = \"llm_dataflow_analysis.json\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'r') as f:\n",
    "        validated_results = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    validated_results = {}\n",
    "\n",
    "processed = 0\n",
    "seen_pairs = set()\n",
    "\n",
    "for pair in found_pairs:\n",
    "    func_name = pair[\"function\"]\n",
    "    allocator = pair[\"allocator\"]\n",
    "    deallocator = pair[\"deallocator\"]\n",
    "    \n",
    "    pair_key = f\"{allocator}|{deallocator}\"\n",
    "    if pair_key in seen_pairs:\n",
    "        continue\n",
    "    \n",
    "    seen_pairs.add(pair_key)\n",
    "    query = f'''\n",
    "def source = cpg.method(\"{func_name}\").call(\"{allocator}\")\n",
    "def sink = cpg.method(\"{func_name}\").call(\"{deallocator}\").argument\n",
    "sink.reachableByFlows(source).p\n",
    "'''\n",
    "    \n",
    "    result = joern_client.execute(query)\n",
    "    stdout = result['stdout'].strip()\n",
    "    \n",
    "    if not stdout or '┌──' not in stdout:\n",
    "        continue\n",
    "\n",
    "    flow_path = stdout\n",
    "    if '\"\"\"' in stdout:\n",
    "        flow_path = stdout.split('\"\"\"')[1].strip()\n",
    "    \n",
    "    context_code = bfs_call_graph(func_name, max_depth=3)\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this DATA FLOW path in C code.\n",
    "\n",
    "CONTEXT (call graph, depth <= 3):\n",
    "{context_code[:4000]}\n",
    "\n",
    "DATA FLOW PATH found by static analysis:\n",
    "{flow_path[:2000]}\n",
    "\n",
    "Question: Does this data flow represent an IDEOLOGICAL allocation-deallocation pair?\n",
    "- {allocator} allocates memory\n",
    "- Memory flows through variables: {flow_path.split('│')[1:3] if '│' in flow_path else 'N/A'}\n",
    "- {deallocator} receives that memory as argument\n",
    "\n",
    "Is this a meaningful pair (like malloc/free) or just coincidental?\n",
    "Return JSON: {{\"is_ideological_pair\": true/false, \"confidence\": 0-100, \"dataflow_analysis\": \"analyze the actual flow path\"}}\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    chat_response = mistral_client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    raw_output = chat_response.choices[0].message.content\n",
    "    \n",
    "    try:\n",
    "        json_output = json.loads(raw_output)\n",
    "        \n",
    "        validated_results[pair_key] = {\n",
    "            \"allocator\": allocator,\n",
    "            \"deallocator\": deallocator,\n",
    "            \"is_ideological_pair\": json_output.get(\"is_ideological_pair\", False),\n",
    "            \"confidence\": json_output.get(\"confidence\", 0),\n",
    "            \"dataflow_analysis\": json_output.get(\"dataflow_analysis\", \"\"),\n",
    "            \"example_function\": func_name,\n",
    "            \"flow_path_preview\": flow_path[:500]\n",
    "        }\n",
    "        \n",
    "        if processed % 3 == 0:\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(validated_results, f, indent=2)\n",
    "        \n",
    "        processed += 1\n",
    "        time.sleep(6.0)\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(validated_results, f, indent=2)\n",
    "\n",
    "ideological_pairs = []\n",
    "for result in validated_results.values():\n",
    "    if result.get(\"is_ideological_pair\", False) and result.get(\"confidence\", 0) > 75:\n",
    "        ideological_pairs.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "Expected result\n",
    "\n",
    "cJSON_New_Item -> cJSON_Delete\n",
    "cJSON_CreateString -> cJSON_Delete\n",
    "cJSON_CreateArray -> cJSON_Delete\n",
    "cJSON_CreateObject -> cJSON_Delete\n",
    "cJSON_CreateRaw -> cJSON_Delete\n",
    "cJSON_strdup -> cJSON_free\n",
    "cJSON_malloc -> cJSON_free\n",
    "cJSON_ParseWithLengthOpts -> cJSON_Delete\n",
    "cJSON_Duplicate -> cJSON_Delete\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
